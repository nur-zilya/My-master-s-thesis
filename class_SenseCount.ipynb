{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "262e1a56",
      "metadata": {
        "id": "262e1a56"
      },
      "outputs": [],
      "source": [
        "!pip install ruwordnet\n",
        "!ruwordnet download\n",
        "!pip install textract\n",
        "from ruwordnet import RuWordNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fd56209",
      "metadata": {
        "id": "9fd56209"
      },
      "outputs": [],
      "source": [
        "!pip uninstall spacy -y\n",
        "!pip install -U spacy>=3.0\n",
        "!python -m spacy download ru_core_news_md\n",
        "import spacy\n",
        "nlp = spacy.load('ru_core_news_md')\n",
        "nlp.max_length = 10000000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f107ffd",
      "metadata": {
        "id": "7f107ffd"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download ('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from math import log, prod"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "F27DrqIp_Wfs"
      },
      "id": "F27DrqIp_Wfs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "575e3271",
      "metadata": {
        "id": "575e3271"
      },
      "outputs": [],
      "source": [
        "from nltk.classify.textcat import TextCat\n",
        "class SenseCounter:\n",
        "\n",
        "    def __init__(self, text):\n",
        "        self.text = text\n",
        "        self.wn = RuWordNet()\n",
        "\n",
        "\n",
        "    def count_senses(self, product=False):\n",
        "        document = nlp(self.text)\n",
        "        outname = path.replace('.docx', '-lemmatized.txt')\n",
        "        print(outname)\n",
        "        with open(outname, 'w', encoding='windows-1251') as out:\n",
        "            for token in document:\n",
        "                out.write(token.lemma_.lower())\n",
        "                out.write(' ')\n",
        "        path_lem = outname\n",
        "        text_lem = open(path_lem, encoding='windows-1251').read()\n",
        "        dict_senses = {}\n",
        "        tokens = nltk.word_tokenize(text_lem)\n",
        "        for word in tokens:\n",
        "            dict_senses[word] = []\n",
        "            for sense in self.wn.get_senses(word):\n",
        "                dict_senses[word].append(sense.synset)\n",
        "        len_tokens = len(tokens)\n",
        "        print(len_tokens)\n",
        "        print(len(dict_senses))\n",
        "        print(dict_senses)\n",
        "        sense_amount = {}\n",
        "        for key, val in dict_senses.items():\n",
        "            sense_amount[key] = len(val)\n",
        "        only_multiples = {}\n",
        "        for key, val in sense_amount.items():\n",
        "            if val > 1:\n",
        "                only_multiples[key] = val\n",
        "        multiple_words_amount = len(only_multiples)\n",
        "        print(multiple_words_amount)\n",
        "        values = []\n",
        "        for key, val in only_multiples.items():\n",
        "            values.append(val)\n",
        "        prod = math.prod(values)\n",
        "        if product==False:\n",
        "            print(multiple_words_amount/len_tokens)\n",
        "        else:\n",
        "            print(math.log10(prod // len_tokens))\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b675c29",
      "metadata": {
        "id": "8b675c29"
      },
      "outputs": [],
      "source": [
        "for file in list_of_files:\n",
        "  path = f\"/content/drive/MyDrive/Thesis/data/{file}\"\n",
        "  text = open(path, encoding='utf-8').read()\n",
        "  init_class = SenseCounter(text)\n",
        "  init_class.count_senses(product=True)\n",
        "  init_class.count_senses(product=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  path = \"/content/drive/Thesis/data/Tbook(M)_R_R_05_05_ByKi_0_A_0_2015_80486.docx\"\n",
        "  text = open(path, encoding='utf-8').read()\n",
        "  init_class = SenseCounter(text)\n",
        "  init_class.count_senses(product=True)\n",
        "  init_class.count_senses(product=False)"
      ],
      "metadata": {
        "id": "PlYoWS7oMn_g"
      },
      "id": "PlYoWS7oMn_g",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}